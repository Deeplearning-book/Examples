{"cells":[{"cell_type":"markdown","metadata":{"id":"Fbj9e4ijTG9N"},"source":["***Sentiment analysis using GRU and Keras***\n","\n","Sentiment analysis is a technique used in natural language processing to determine the polarity of a given text. There are several types of sentiment analysis, but one of the most generally used ways categorizes data as positive or negative. This aids in the study of various text elements, such as comments, tweets, and customer reviews, in order to understand the insights and feedbacks from the audience.\n","\n","Let us see how we can implement this in Keras.\n","\n","This example is based on the following [link](https://medium.com/@prateekgaurav/nlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44#:~:text=To%20use%20a%20GRU%20for,model%20using%20the%20Keras%20API.&text=The%20GRU%20model%20performed%20almost,raw%20text%20and%20early%20stopping.).\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"QzORsms18hHQ"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"i4NH3naUVRC5"},"source":["**Importing packages**\n","\n","For this version, we call the keras modules for building the model and the nltk package and modules are imported for preprocessing the text data."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7068,"status":"ok","timestamp":1682621565334,"user":{"displayName":"Aswathy","userId":"06157770311800271718"},"user_tz":420},"id":"fQvu7HO0YwHF","outputId":"3334ef8f-6868-417e-ec59-fb289617868e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\aswathyr\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\aswathyr\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from __future__ import print_function\n","\n","# import keras libraries for building GRU\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding\n","from keras.layers import GRU\n","from keras.datasets import imdb\n","\n","# import nltk and other submodules for preprocessing the data\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","import re\n","\n","nltk.download('punkt')\n","nltk.download(\"stopwords\")"]},{"cell_type":"markdown","metadata":{"id":"k46T6n3lDfQ8"},"source":["**Loading the dataset**\n","\n","Let us load the IMDB dataset and divide it into train and test sets."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6475,"status":"ok","timestamp":1682621575934,"user":{"displayName":"Aswathy","userId":"06157770311800271718"},"user_tz":420},"id":"AAnIRQOjdpMA","outputId":"c3e4c440-a1eb-40ed-8853-7d614d8da09f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data...\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","25000 train sequences\n","25000 test sequences\n"]}],"source":["max_features = 20000\n","maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n","batch_size = 32\n","\n","print('Loading data...')\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","print(len(x_train), 'train sequences')\n","print(len(x_test), 'test sequences')"]},{"cell_type":"markdown","metadata":{"id":"z4qI5IPU-Pgk"},"source":["## Preprocessing step ##\n","\n","Once the data is loaded, we pad the sequences to a maximum length using _pad_sequences_ method.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":894,"status":"ok","timestamp":1682621590232,"user":{"displayName":"Aswathy","userId":"06157770311800271718"},"user_tz":420},"id":"R60CSEMhZJwp","outputId":"83eb0d59-8163-4f8f-ef06-ccfe1e934807"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pad sequences (samples x time)\n","x_train shape: (25000, 80)\n","x_test shape: (25000, 80)\n"]}],"source":["from keras.utils import pad_sequences\n","print('Pad sequences (samples x time)')\n","x_train = pad_sequences(x_train, maxlen=maxlen)\n","x_test = pad_sequences(x_test, maxlen=maxlen)\n","print('x_train shape:', x_train.shape)\n","print('x_test shape:', x_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"-f2ePlCKHoE8"},"source":["## Create the GRU model ##\n","\n","Using the sequential class, we create the GRU model and add  different layers to it such as _embedding_, _GRU_, _dense_ and _dropout_ layer."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":538,"status":"ok","timestamp":1682621592898,"user":{"displayName":"Aswathy","userId":"06157770311800271718"},"user_tz":420},"id":"kzHbC39YZdPg","outputId":"0d581cf5-63a5-4662-cc90-bc8a49268409"},"outputs":[{"name":"stdout","output_type":"stream","text":["Build model...\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["print('Build model...')\n","model = Sequential()\n","model.add(Embedding(max_features, 128))\n","model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Training the model"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"lxhcia2fZmkg"},"outputs":[],"source":["# try using different optimizers and different optimizer configs\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300773,"status":"ok","timestamp":1682621902015,"user":{"displayName":"Aswathy","userId":"06157770311800271718"},"user_tz":420},"id":"nENO3npBZoCT","outputId":"bb89aec1-96f9-43f7-b9f9-63cd8c642667"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train...\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 32ms/step - accuracy: 0.6973 - loss: 11.9552 - val_accuracy: 0.7439 - val_loss: 0.5230\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x1e9d3547800>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["print('Train...')\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=10,\n","          validation_data=(x_test, y_test))"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluating the scores"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20262,"status":"ok","timestamp":1682621922261,"user":{"displayName":"Aswathy","userId":"06157770311800271718"},"user_tz":420},"id":"d4hw6t9zZtS6","outputId":"8f286e29-bb22-4f91-f3c6-f1864ac2f707"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7422 - loss: 0.5259\n","Test score: 0.5230189561843872\n","Test accuracy: 0.7439200282096863\n"]}],"source":["score, acc = model.evaluate(x_test, y_test,\n","                            batch_size=batch_size)\n","print('Test score:', score)\n","print('Test accuracy:', acc)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
